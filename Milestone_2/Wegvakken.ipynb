{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, requests\n",
    "from pprint import *\n",
    "import csv\n",
    "import collections\n",
    "from unidecode import unidecode\n",
    "import re, requests\n",
    "from rdflib import Dataset, URIRef, Literal, Namespace, RDF, RDFS, OWL, XSD\n",
    "from iribaker import to_iri\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from geomet import wkt\n",
    "# pip install git+git://github.com/geomet/geomet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://geodata.nationaalgeoregister.nl/nwbwegen/wfs?service=WFS&request=GetFeature&typeName=nwbwegen:wegvakken&count=%d&startIndex=%d&outputFormat=json&srsName=EPSG:4326'\n",
    "\n",
    "count = 10\n",
    "startIndex = 0\n",
    "amsterdamData = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def retreiveWegvakken():\n",
    "    count = 10000\n",
    "    startIndex = 1\n",
    "    f = open('amsterdam-wegvakken.csv','wb')\n",
    "    resp = requests.get(url=url % (count, startIndex))\n",
    "    data = json.loads(resp.text)\n",
    "\n",
    "    featuresChecked = 0\n",
    "    totalFeatures = data['totalFeatures']\n",
    "    print totalFeatures\n",
    "\n",
    "    keys = ['coordinates', 'avgCoordinates', 'wtk']\n",
    "    keys += data['features'][0]['properties'].keys()\n",
    "    print keys\n",
    "    w = csv.DictWriter(f,keys)\n",
    "    w.writeheader()\n",
    "\n",
    "    startIndex = 1\n",
    "    filterCity = 'Amsterdam'\n",
    "    while startIndex < totalFeatures:\n",
    "        retry = True\n",
    "        while retry:\n",
    "            try:\n",
    "                resp = requests.get(url=url % (count, startIndex))\n",
    "                retry = False\n",
    "            except Timeout:\n",
    "                print \"retry, connection timed out\"\n",
    "            except Exception:\n",
    "                print \"some other error, Exit!\"\n",
    "                return\n",
    "        data = json.loads(resp.text)\n",
    "        print startIndex\n",
    "        for feat in data['features']:\n",
    "            if feat['properties']['gme_naam'] == filterCity:\n",
    "                wegVakData = {}\n",
    "                coordinates = feat['geometry']['coordinates']\n",
    "                avgCoordinates = [sum(i[0] for i in coordinates[0])/len(coordinates[0]), sum(i[1] for i in coordinates[0])/len(coordinates[0])]\n",
    "                wegVakData = feat['properties'].copy()\n",
    "                wegVakData['wtk'] = feat['geometry']\n",
    "                wegVakData['coordinates']    = coordinates\n",
    "                wegVakData['avgCoordinates'] = avgCoordinates\n",
    "                wegVakData =  dict([(k.encode('ascii', 'replace'), v.encode('ascii', 'replace') if type(v) is str or type(v) is unicode else v) for k, v in wegVakData.items()])\n",
    "                w.writerow(wegVakData)\n",
    "        startIndex += count\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TUTORIAL_REPOSITORY = \"http://stardog.krw.d2s.labs.vu.nl/group12\"\n",
    "\n",
    "def upload_to_stardog(data):\n",
    "    transaction_begin_url = TUTORIAL_REPOSITORY + \"/transaction/begin\"\n",
    "    \n",
    "    # Start the transaction, and get a transaction_id\n",
    "    response = requests.post(transaction_begin_url, headers={'Accept': 'text/plain'})\n",
    "    transaction_id = response.content\n",
    "#     print response.status_code\n",
    "#     print response.headers\n",
    "    \n",
    "    # POST the data to the transaction\n",
    "    post_url = TUTORIAL_REPOSITORY + \"/\" + transaction_id + \"/add\"\n",
    "    response = requests.post(post_url, data=data, headers={'Accept': 'text/plain', 'Content-type': 'application/trig'})\n",
    "#     print response.status_code\n",
    "#     print response.headers\n",
    "    \n",
    "    # Close the transaction\n",
    "    transaction_close_url = TUTORIAL_REPOSITORY + \"/transaction/commit/\" + transaction_id\n",
    "    response = requests.post(transaction_close_url)\n",
    "#     print response.status_code\n",
    "#     print response.headers\n",
    "    \n",
    "    return str(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VALID_CHARS = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wegvakken = csv.DictReader(open('amsterdam-wegvakken.csv', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A namespace for our resources\n",
    "data = 'http://data.krw.d2s.labs.vu.nl/group12/resource/'\n",
    "DATA = Namespace(data)\n",
    "# A namespace for our vocabulary items (schema information, RDFS, OWL classes and properties etc.)\n",
    "vocab = 'http://data.krw.d2s.labs.vu.nl/group12/vocab/'\n",
    "VOCAB = Namespace('http://data.krw.d2s.labs.vu.nl/group12/vocab/')\n",
    "\n",
    "# The URI for our graph\n",
    "graph_uri = URIRef('http://data.krw.d2s.labs.vu.nl/group12/resource/roadsectiongraph')\n",
    "\n",
    "# We initialize a dataset, and bind our namespaces\n",
    "dataset = Dataset()\n",
    "dataset.bind('g12data', DATA)\n",
    "dataset.bind('g12vocab', VOCAB)\n",
    "\n",
    "# We then get a new graph object with our URI from the dataset.\n",
    "graph = dataset.graph(graph_uri)\n",
    "\n",
    "# Create namespaces for our Geo-data\n",
    "GSP = Namespace('http://www.opengis.net/ont/geosparql#')\n",
    "GSF = Namespace('http://www.opengis.net/ont/sf#')\n",
    "# prov = Namespace('http://www.w3.org/ns/prov#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "dataset = Dataset()\n",
    "dataset.bind('g12data',DATA)\n",
    "dataset.bind('g12vocab',VOCAB)\n",
    "dataset.default_context.parse('vocab.ttl', format='turtle')\n",
    "graph = dataset.graph(graph_uri)\n",
    "'''\n",
    "dataset.default_context.parse('vocab.ttl', format='turtle')\n",
    "\n",
    "uploadCount = 0\n",
    "for row in wegvakken:\n",
    "    # first create the URI's\n",
    "    wegvak = URIRef(to_iri(data + 'RoadSection/' + row['wvk_id']))\n",
    "    jte_beg = URIRef(to_iri(data + 'Junction/' + row['jte_id_beg']))\n",
    "    jte_end = URIRef(to_iri(data + 'Junction/' + row['jte_id_end']))\n",
    "    hnrstrrhts = Literal(row['hnrstrrhts'], datatype=XSD['string'])\n",
    "    hnrstrlnks = Literal(row['hnrstrlnks'], datatype=XSD['string'])\n",
    "    e_hnr_rhts = Literal(row['e_hnr_rhts'], datatype=XSD['int'])\n",
    "    e_hnr_lnks = Literal(row['e_hnr_lnks'], datatype=XSD['int'])\n",
    "    l_hnr_rhts = Literal(row['l_hnr_rhts'], datatype=XSD['int'])\n",
    "    stt_naam = ''.join([c for c in row['stt_naam'].strip() if c in VALID_CHARS])\n",
    "    straatUri = URIRef(to_iri(data + stt_naam))\n",
    "    gemeenteNaam = ''.join([c for c in row['gme_naam'].strip() if c in VALID_CHARS])\n",
    "    dorp = URIRef(to_iri(data + gemeenteNaam))\n",
    "#     wegvak_MLS = URIRef(to_iri(data + 'RoadSection/' + row['wvk_id'] + '/MultiLineString'))\n",
    "    jte_beg_Point = URIRef(to_iri(data + 'Junction/' + row['jte_id_beg'] + '/Point'))\n",
    "    jte_end_Point = URIRef(to_iri(data + 'Junction/' + row['jte_id_end'] + '/Point'))\n",
    "\n",
    "    #then the literals\n",
    "    wegvakNaam = Literal('RoadSection' + row['wvk_id'], datatype=XSD['string'])\n",
    "    wegvakid = Literal(row['wvk_id'], datatype=XSD['int'])\n",
    "    straatNaam = Literal(row['stt_naam'].strip(), lang='nl')\n",
    "    l_hnr_lnks = Literal(row['l_hnr_lnks'], datatype=XSD['int'])\n",
    "    rijrichtng = Literal(row['rijrichtng'], datatype=XSD['string'])\n",
    "    wegbehsrt = Literal(row['wegbehsrt'], datatype=XSD['string'])\n",
    "    gemid = Literal(row['gme_id'], datatype=XSD['int'])\n",
    "    gemeente = Literal(row['gme_naam'], lang='nl')\n",
    "    jte_beg_id = Literal(row['jte_id_beg'], datatype=XSD['int'])\n",
    "    jte_end_id = Literal(row['jte_id_end'], datatype=XSD['int'])\n",
    "    jte_beg_naam = Literal('Junction' + row['jte_id_beg'], datatype=XSD['string'])\n",
    "    jte_end_naam = Literal('Junction' + row['jte_id_end'], datatype=XSD['string'])\n",
    "    tempCoordinates = json.loads(row['coordinates'])[0]\n",
    "    begPoint = Literal('POINT({} {})'.format(tempCoordinates[0][0], tempCoordinates[0][1]), datatype=GSP.wktLiteral)\n",
    "    endPoint = Literal('POINT({} {})'.format(tempCoordinates[-1][0], tempCoordinates[-1][1]), datatype=GSP.wktLiteral)\n",
    "\n",
    "#     parsedCoordinates = wkt.dumps({'type': 'MultiLineString', 'coordinates': json.loads(row['coordinates'])})\n",
    "#     coords = Literal(parsedCoordinates, datatype=GSP.wktLiteral)\n",
    "\n",
    "    graph.add((wegvak, RDFS.label, wegvakNaam))\n",
    "    graph.add((wegvak, RDF.type, VOCAB['RoadSection']))\n",
    "    graph.add((wegvak, VOCAB['wvk_id'], wegvakid))\n",
    "    graph.add((straatUri, RDF.type, VOCAB['Street']))\n",
    "    graph.add((straatUri, RDFS.label, straatNaam))\n",
    "    graph.add((wegvak, VOCAB['street'], straatUri))\n",
    "    graph.add((dorp, RDF.type, VOCAB['Town']))\n",
    "    graph.add((dorp, VOCAB['gme_naam'], gemeente))\n",
    "    graph.add((dorp, VOCAB['gme_id'], gemid))\n",
    "    graph.add((wegvak, VOCAB['town'], dorp))\n",
    "    graph.add((wegvak, VOCAB['hnrstrrhts'], hnrstrrhts))\n",
    "    graph.add((wegvak, VOCAB['hnrstrlnks'], hnrstrlnks))\n",
    "    graph.add((wegvak, VOCAB['e_hnr_rhts'], e_hnr_rhts))\n",
    "    graph.add((wegvak, VOCAB['e_hnr_lnks'], e_hnr_lnks))\n",
    "    graph.add((wegvak, VOCAB['l_hnr_rhts'], l_hnr_rhts))\n",
    "    graph.add((wegvak, VOCAB['l_hnr_lnks'], l_hnr_lnks))\n",
    "    graph.add((wegvak, VOCAB['rijrichtng'], rijrichtng))\n",
    "    graph.add((wegvak, VOCAB['wegbehsrt'], wegbehsrt))\n",
    "    graph.add((jte_beg, RDF.type, VOCAB['Junction']))\n",
    "    graph.add((jte_beg, RDFS.label, jte_beg_naam))\n",
    "    graph.add((jte_beg, VOCAB['jte_id'], jte_beg_id))\n",
    "    graph.add((jte_beg, GSP.hasGeometry, jte_beg_Point))\n",
    "    graph.add((jte_beg_Point, RDF.type, GSF.Point))\n",
    "    graph.add((jte_beg_Point, GSP.asWKT, begPoint))\n",
    "    graph.add((jte_end, RDF.type, VOCAB['Junction']))\n",
    "    graph.add((jte_end, RDFS.label, jte_end_naam))\n",
    "    graph.add((jte_end, VOCAB['jte_id'], jte_end_id))\n",
    "    graph.add((jte_end, GSP.hasGeometry, jte_end_Point))\n",
    "    graph.add((jte_end_Point, RDF.type, GSF.Point))\n",
    "    graph.add((jte_end_Point, GSP.asWKT, endPoint))\n",
    "    graph.add((wegvak, VOCAB['junction_beg'], jte_beg))\n",
    "    graph.add((wegvak, VOCAB['junction_end'], jte_end))\n",
    "#     graph.add((wegvak, GSP.hasGeometry, wegvak_MLS))\n",
    "#     graph.add((wegvak_MLS, RDF.type, GSF.MultiLineString))\n",
    "#     graph.add((wegvak_MLS, GSP.asWKT, coords))  # Stardog does not support MLS out-of-the-box; omitted for now\n",
    "    '''\n",
    "    print dataset.serialize(format='trig')\n",
    "    print 'response.status_code = ' + upload_to_stardog(dataset.serialize(format='trig'))\n",
    "    break\n",
    "    '''\n",
    "    uploadCount = uploadCount + 1\n",
    "    if uploadCount % 400 == 0:\n",
    "#         print 'response.status_code = ' + upload_to_stardog(dataset.serialize(format='trig'))\n",
    "        \n",
    "        # We reset the dataset (so we don't re-upload prevously uploaded data), and bind our namespaces\n",
    "        dataset = Dataset()\n",
    "        dataset.bind('g12data', DATA)\n",
    "        dataset.bind('g12vocab', VOCAB)\n",
    "\n",
    "        # We then get a new graph object with our URI from the dataset.\n",
    "        graph = dataset.graph(graph_uri)\n",
    "\n",
    "# upload the final bit of data\n",
    "# print str(uploadCount) + ': response.status_code = ' + upload_to_stardog(dataset.serialize(format='trig'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print dataset.serialize(format='trig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('temp-roadsections-rdf.trig','w') as f:\n",
    "#     dataset.serialize(f, format='trig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
